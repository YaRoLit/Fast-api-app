import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re
import pymorphy2
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
from wordcloud import WordCloud
import os


st.set_page_config(layout="wide", page_title="Day_stats", page_icon="üìà")   # –ü–æ–ª–Ω–æ–æ–∫–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.write("# –ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–∞—Ç–µ –∏–ª–∏ –ø–µ—Ä–∏–æ–¥—É")


def find_files():
    for files in os.walk('./Data/'):
        files = files[2]
        files.remove('tracks.txt')
        files = pd.Series(files)
        return files

def preprocess(lst):
    '''–§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π, –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –µ–≥–æ,
       –∏ –≤–æ–∑–≤—Ä–∞—â–µ—Ç –≤ –≤–∏–¥–µ –º–µ—à–∫–∞ —Å–ª–æ–≤'''
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    bag = ' '.join(lst).lower()
    # –£–±–∏—Ä–∞–µ–º —Ü–∏—Ñ—Ä—ã
    numbers = re.compile(r'\d+')
    bag = re.sub(numbers, '', bag)
    # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    punct = re.compile(r'[^\w\s]')
    bag = re.sub(punct, '', bag)
    # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏
    url = re.compile(r'((?<=[^a-zA-Z0-9])(?:https?\:\/\/|[a-zA-Z0-9]{1,}\.{1}|\b)(?:\w{1,}\.{1}){1,5}(?:com|co|org|edu|gov|uk|net|ca|de|jp|fr|au|us|ru|ch|it|nl|se|no|es|mil|iq|io|ac|ly|sm){1}(?:\/[a-zA-Z0-9]{1,})*)')
    bag = re.sub(url, '', bag)
    # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã:
    symbols = re.compile(r'\n')
    bag = re.sub(symbols, '', bag)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    #extra_spaces = re.compile(r'\s{2,}')
    #bag = re.sub(extra_spaces, ' ', bag)
    # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –æ—Ç —Å—Ç–æ–ø—Å–ª–æ–≤
    morph = pymorphy2.MorphAnalyzer()
    stop = stopwords.words('russian')
    stop.extend(['—ç—Ç–æ', '–≤–µ—Å—å', '–≤—Å—ë', '–Ω–∞—à', '–≤–∞—à', '–∫–æ—Ç–æ—Ä—ã–π', '–ø–æ—á–µ–º—É'])
    bag = [morph.normal_forms(word)[0] for word in bag.split() if word not in stop]
    return ' '.join(bag)

def show_wordcloud(bag):
    '''
    –†–∏—Å—É–µ–º –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤
    '''
    wordcloud = WordCloud(
            width = 800, 
            height = 800,
            background_color ='white',
            min_font_size = 10
        ).generate(bag)

    ff = plt.figure(figsize=(5, 5))
    plt.imshow(wordcloud)
    plt.axis('off')
    st.pyplot(ff) 

def make_clouds(df):
    '''
    –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –Ω–∞–¥–ø–∏—Å—å cloud, —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –æ–±–ª–∞–∫–æ–≤ —Å–ª–æ–≤
    –í–æ—Ç –∏–º–µ–Ω–Ω–æ —ç—Ç–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—à–∫–∏ —Å–ª–æ–≤ –ø–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º –∫–æ–º–º–µ–Ω—Ç–∞–º –∏ –ø–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º
    '''
    positive_list = []
    negative_list = []
    positive_texts = df.index[df.loc[:, 'sentiment'] == 'POSITIVE'].tolist()
    for idx in positive_texts:
        positive_list.append(df.loc[idx, 'text'])

    negative_texts = df.index[df.loc[:, 'sentiment'] == 'NEGATIVE'].tolist()
    for idx in negative_texts:
        negative_list.append(df.loc[idx, 'text'])

    positive_bag = preprocess(positive_list)
    negative_bag = preprocess(negative_list)

    return positive_bag, negative_bag


col1, col2 = st.columns(2)
with col1:
    files = find_files()
    uploaded_file = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —á–∞—Ç–∞", files) #
    uploaded_file = './Data/' + uploaded_file

with col2:
    dt = st.date_input("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â—É—é –¥–∞—Ç—É")
    result = st.button('–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç—É')

if result & (uploaded_file is not None):
    df = pd.read_csv(uploaded_file, sep='\t', encoding='utf-8')
    dt = str(dt)
    if dt in df.date.unique():
        idx = df.date == dt

        col1, col2, col3 = st.columns(3)
        with col1:
            st.write(f'–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ {dt}')
            sentiment_data = df[idx].sentiment.value_counts()
            fig = plt.figure(figsize=(4, 4))
            ax = fig.add_axes((1, 1, 1, 1))
            ax.pie(sentiment_data,
                explode = [0.1, 0.1, 0.1],
                autopct='%1.1f%%',
                textprops={'fontsize': 14},
                labels=sentiment_data.index,
                shadow=True)
            #ax.set_title(f'–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π {dt}', size=24)
            st.pyplot(fig)

        with col2:
            st.write('–û–±–ª–∞–∫–æ —Å–ª–æ–≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤')
            show_wordcloud(make_clouds(df[idx])[0])

        with col3:
            st.write('–û–±–ª–∞–∫–æ —Å–ª–æ–≤ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤')
            show_wordcloud(make_clouds(df[idx])[1])
        
            dn = df[idx].drop(columns=['datetime', 'date', 'user_id', 'nickname', 'second_name'])    # –î–ª—è –æ–±—â–µ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞–º —ç—Ç–∏ —Å—Ç–æ–ª–±—Ü—ã –Ω–µ –Ω—É–∂–Ω—ã
            st.write(f'–°–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞ –∑–∞ {dt}')
            st.dataframe(dn, width=1000, height=500)

    else:
        st.error('–î–∞—Ç–∞ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞', icon="üö®")

